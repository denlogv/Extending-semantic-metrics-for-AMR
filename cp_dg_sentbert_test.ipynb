{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Test scripts for Benepar, SuPar, SentenceTransformers APIs</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from supar import Parser\n",
    "from nltk.tree import Tree\n",
    "import spacy; nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constituency Parsing using Benepar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package benepar_en2 to C:\\Users\\Denis\n",
      "[nltk_data]     Logvinenko\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package benepar_en2 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import benepar\n",
    "from benepar.spacy_plugin import BeneparComponent\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "benepar_ver = 'benepar_en2'\n",
    "benepar.download(benepar_ver)\n",
    "\n",
    "model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n",
    "nlp.add_pipe(BeneparComponent(benepar_ver))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (DT The) (NN kitten))\n",
      "  (VP\n",
      "    (VBZ is)\n",
      "    (VP (VBG running) (PP (IN through) (NP (DT a) (NN gate))))))\n",
      "(S (NP (DT A) (JJ young) (NN cat)) (VP (VBZ sprints)))\n"
     ]
    }
   ],
   "source": [
    "texts = [\"The kitten is running through a gate\", \"A young cat sprints\"]\n",
    "docs = list(nlp.pipe(texts))\n",
    "\n",
    "trees = [Tree.fromstring(list(doc.sents)[0]._.parse_string) for doc in docs]\n",
    "for tree in trees: print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependecy Parsing using SuPar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = Parser.load('crfnp-dep-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|####################################| 1/1 00:00<00:00, 32.38it/s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\tThe\t_\t_\t_\t_\t2\tdet\t_\t_\n",
      "2\thouse\t_\t_\t_\t_\t2\tamod\t_\t_\n",
      "3\twas\t_\t_\t_\t_\t4\tauxpass\t_\t_\n",
      "4\tsold\t_\t_\t_\t_\t4\tccomp\t_\t_\n",
      "5\tin\t_\t_\t_\t_\t4\tprep\t_\t_\n",
      "6\ttime\t_\t_\t_\t_\t5\tpobj\t_\t_\n",
      "\n",
      "1\tThey\t_\t_\t_\t_\t2\tnsubj\t_\t_\n",
      "2\tsold\t_\t_\t_\t_\t2\tdep\t_\t_\n",
      "3\tthe\t_\t_\t_\t_\t4\tdet\t_\t_\n",
      "4\thouse\t_\t_\t_\t_\t4\tdep\t_\t_\n",
      "5\tin\t_\t_\t_\t_\t2\tprep\t_\t_\n",
      "6\ttime\t_\t_\t_\t_\t5\tpobj\t_\t_\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text = ['The house was sold in time', 'They sold the house in time']\n",
    "docs = list(nlp.pipe(text))\n",
    "toks = [[tok.text for tok in doc] for doc in docs]; print(len(toks))\n",
    "dataset = parser.predict(toks, prob=True, verbose=False)\n",
    "pars = dataset.sentences\n",
    "\n",
    "for par in pars: print(par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Phrase Similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The kitten \t\t A young cat \t\t Score: 0.6921\n",
      "The kitten \t\t a mouse \t\t Score: 0.2679\n"
     ]
    }
   ],
   "source": [
    "sentences1, sentences2 = nps\n",
    "\n",
    "#Compute embedding for both lists\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "#Compute cosine-similarits\n",
    "cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "#Output the pairs with their score\n",
    "for i in range(cosine_scores.shape[0]):\n",
    "    for j in range(cosine_scores.shape[1]):\n",
    "        print(f'{sentences1[i]} \\t\\t {sentences2[j]} \\t\\t Score: {cosine_scores[i, j]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amrozi accused his brother, whom he called \"the witness\", of deliberately distorting his evidence. \t\t Referring to him as only \"the witness\", Amrozi accused his brother of deliberately distorting his evidence. \t\t Score: 0.9297\n"
     ]
    }
   ],
   "source": [
    "s1 = ['Amrozi accused his brother, whom he called \"the witness\", of deliberately distorting his evidence.']\n",
    "s2 = ['Referring to him as only \"the witness\", Amrozi accused his brother of deliberately distorting his evidence.']\n",
    "\n",
    "embeddings1 = model.encode(s1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(s2, convert_to_tensor=True)\n",
    "\n",
    "#Compute cosine-similarits\n",
    "cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "#Output the pairs with their score\n",
    "for i in range(cosine_scores.shape[0]):\n",
    "    for j in range(cosine_scores.shape[1]):\n",
    "        print(f'{s1[i]} \\t\\t {s2[j]} \\t\\t Score: {cosine_scores[i, j]:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
